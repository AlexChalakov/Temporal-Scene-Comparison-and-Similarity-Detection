# Temporal-Scene-Comparison-and-Similarity-Detection

As advancements in Machine Learning are growing rapidly, Convolutional Neural Networks (CNNs) find their way to be utilised in a large number of innovative and cutting-edge image recognition and computer vision tasks. Temporal scene comparison and similarity detection algorithms are crucial for the detection of similarities and differences between images, which can be used to identify individuals or objects that match a specific pattern, such as a wanted criminal or a missing person.

They face multiple challenges in the sphere of image classification in the form of changes in illumination, rotation, translation, and posture, with many various approaches to overcome these limitations, including Siamese Networks, Scale Invariant Features Transform (SIFT), and Class Activation Maps (CAM). This report investigates and focuses on the analysis of the results from deploying and applying those algorithms on a large database and their subsequent behaviour.

This large database is restructured in a way that matches the requirements of the algorithms, whilst underlining the importance of data preparation in Machine Learning projects. We investigate the effectiveness of the Siamese Networks in identifying pairs of images with a ground truth relationship, which can face flaws in close scenarios in the form of False positives and False
negatives.

For this purpose, we also deploy the SIFT, which is a far more demonstrable and explainable approach. It reveals to us the reason the Siamese Network might be wrong and gives us an additional output of the results, achieving a valid hypothesis for a hybrid approach that can successfully classify and compare photos, detecting how similar they are at the same time. A demonstration model is prepared and is further explored how the application of these models can be influential in medical diagnostics and open court.
